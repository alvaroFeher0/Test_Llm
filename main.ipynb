{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0735d835",
   "metadata": {},
   "source": [
    "# TEST LLM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfda6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='qwen2.5:7b-instruct' created_at='2025-10-25T11:02:48.947815Z' done=True done_reason='stop' total_duration=13472188167 load_duration=75108708 prompt_eval_count=30 prompt_eval_duration=196175250 eval_count=287 eval_duration=13109531968 message=Message(role='assistant', content='Certainly! Here\\'s a simple Python function to merge two dictionaries:\\n\\n```python\\ndef merge_dicts(dict1, dict2):\\n    \"\"\"\\n    Merge two dictionaries into one.\\n\\n    Parameters:\\n    - dict1 (dict): The first dictionary.\\n    - dict2 (dict): The second dictionary.\\n\\n    Returns:\\n    - merged_dict (dict): A new dictionary containing all key-value pairs from both input dictionaries. \\n                          If there are overlapping keys, the values from dict2 will overwrite those from dict1.\\n    \"\"\"\\n    merged_dict = {**dict1, **dict2}\\n    return merged_dict\\n\\n# Example usage\\ndict_a = {\\'a\\': 1, \\'b\\': 2}\\ndict_b = {\\'b\\': 3, \\'c\\': 4}\\n\\nmerged_dict = merge_dicts(dict_a, dict_b)\\nprint(merged_dict)  # Output: {\\'a\\': 1, \\'b\\': 3, \\'c\\': 4}\\n```\\n\\n### Explanation:\\n- The function `merge_dicts` takes two dictionaries (`dict1` and `dict2`) as arguments.\\n- It uses the dictionary unpacking operator (`**`) to merge the two dictionaries. This creates a new dictionary that includes all key-value pairs from both input dictionaries, with values from `dict2` taking precedence in case of key collisions.\\n\\nThis method is concise and leverages Python\\'s built-in functionality for handling dictionaries efficiently.', thinking=None, images=None, tool_name=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from ollama import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf444fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.chat(model='qwen2.5:7b-instruct',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful software development assistant.'},\n",
    "        {'role': 'user', 'content': 'Write a Python function that merges two dictionaries.'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(res['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eeb6e6",
   "metadata": {},
   "source": [
    "Testing LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c313a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/2sb8f30d6lbdtbjx0srpm0180000gn/T/ipykernel_39224/3699322809.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"qwen2.5:7b-instruct\", temperature=0.7)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5:7b-instruct\", temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"Explain decorators in Python in simple terms.\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da8c07",
   "metadata": {},
   "source": [
    "## Creating Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccabc7",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abec2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def find_top_scorer(scores_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a JSON string with player scores, return the name of the player with the highest score.\n",
    "    Example input:\n",
    "    '{\"Alice\": 10, \"Bob\": 7, \"Charlie\": 12}'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scores = json.loads(scores_json)\n",
    "        if not isinstance(scores, dict):\n",
    "            return \"Invalid JSON format. Expected a dictionary of player: score.\"\n",
    "\n",
    "        top_player = max(scores, key=scores.get)\n",
    "        top_score = scores[top_player]\n",
    "        return f\"{top_player} scored the most with {top_score} points.\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Invalid JSON format. Could not parse input.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List, Optional, Dict, Any\n",
    "import json\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from collections import defaultdict\n",
    "\n",
    "@tool\n",
    "def most_productive_day(tasks_json: str,\n",
    "                        metric: str = \"completed_count\",\n",
    "                        tz: str = \"Europe/Madrid\") -> str:\n",
    "    \"\"\"\n",
    "    Determine the most productive weekday from a JSON list of tasks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tasks_json : str\n",
    "        JSON string of a list of task objects. Each task can include:\n",
    "          - id: str\n",
    "          - title: str\n",
    "          - created_at: ISO 8601 datetime string\n",
    "          - completed_at: ISO 8601 datetime string or null\n",
    "          - duration_minutes: int (optional)\n",
    "          - points: float|int (optional)\n",
    "          - tags: list[str] (optional)\n",
    "          - status: \"todo\" | \"in_progress\" | \"done\" (optional)\n",
    "    metric : str\n",
    "        Productivity metric. One of:\n",
    "          - \"completed_count\" (default): count tasks completed per weekday\n",
    "          - \"duration_sum\": sum of duration_minutes of completed tasks per weekday\n",
    "          - \"points_sum\": sum of points of completed tasks per weekday\n",
    "    tz : str\n",
    "        IANA timezone name for day bucketing. Default: \"Europe/Madrid\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        JSON string with:\n",
    "          - metric_used\n",
    "          - timezone\n",
    "          - winner: {\"weekday\": \"Mon\", \"value\": 12}\n",
    "          - breakdown: [{\"weekday\":\"Mon\",\"value\":...}, ...] ordered Mon..Sun\n",
    "          - notes\n",
    "    \"\"\"\n",
    "    def parse_dt(s: Optional[str]) -> Optional[datetime]:\n",
    "        if not s:\n",
    "            return None\n",
    "        # Accept both with/without timezone; assume UTC if naive\n",
    "        try:\n",
    "            dt = datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
    "        except Exception:\n",
    "            return None\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=ZoneInfo(\"UTC\"))\n",
    "        return dt.astimezone(ZoneInfo(tz))\n",
    "\n",
    "    try:\n",
    "        tasks: List[Dict[str, Any]] = json.loads(tasks_json)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Invalid JSON: {e}\"})\n",
    "\n",
    "    # Initialize weekday buckets Mon..Sun\n",
    "    order = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    agg = defaultdict(float)\n",
    "\n",
    "    for t in tasks:\n",
    "        completed = parse_dt(t.get(\"completed_at\"))\n",
    "        if not completed:\n",
    "            continue  # only count completed items\n",
    "\n",
    "        weekday = order[completed.weekday()]  # 0=Mon\n",
    "        if metric == \"completed_count\":\n",
    "            agg[weekday] += 1\n",
    "        elif metric == \"duration_sum\":\n",
    "            agg[weekday] += float(t.get(\"duration_minutes\") or 0)\n",
    "        elif metric == \"points_sum\":\n",
    "            agg[weekday] += float(t.get(\"points\") or 0)\n",
    "        else:\n",
    "            return json.dumps({\"error\": f\"Unknown metric '{metric}'\"})\n",
    "\n",
    "    breakdown = [{\"weekday\": d, \"value\": agg.get(d, 0)} for d in order]\n",
    "    # Determine winner (tie-breaker: earliest weekday in order)\n",
    "    winner_day, winner_val = max(breakdown, key=lambda x: (x[\"value\"], -order.index(x[\"weekday\"]))) if breakdown else (\"Mon\", 0)\n",
    "\n",
    "    out = {\n",
    "        \"metric_used\": metric,\n",
    "        \"timezone\": tz,\n",
    "        \"winner\": {\"weekday\": winner_day, \"value\": winner_val},\n",
    "        \"breakdown\": breakdown,\n",
    "        \"notes\": [\n",
    "            \"Only completed tasks are counted.\",\n",
    "            \"For naive timestamps, UTC is assumed before converting to the specified timezone.\",\n",
    "            \"Change 'metric' to 'duration_sum' or 'points_sum' to use other productivity measures.\"\n",
    "        ]\n",
    "    }\n",
    "    return json.dumps(out, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c381fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "@tool\n",
    "def balance_teams(players_json: str, events_json: str = \"[]\") -> str:\n",
    "    \"\"\"\n",
    "    Balance players into two teams based on their past performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    players_json : str\n",
    "        JSON string list of player dicts:\n",
    "        [{\"playerId\": \"...\", \"playerName\": \"...\"}, ...]\n",
    "    events_json : str\n",
    "        JSON string list of game events (from the database):\n",
    "        Each event has:\n",
    "            - \"action\": e.g. \"GOL\", \"ASSISTENCIA\", \"FALTA\", \"ATURADA\"\n",
    "            - \"playerId\": str\n",
    "            - \"timestamp\": str or timestamp\n",
    "            - \"finalized\": bool\n",
    "            - other fields ignored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str : JSON string describing team assignments and player scores.\n",
    "        {\n",
    "            \"team_A\": [{\"playerName\": \"Alice\", \"score\": 5.5}, ...],\n",
    "            \"team_B\": [{\"playerName\": \"Bob\", \"score\": 5.2}, ...],\n",
    "            \"notes\": \"Teams balanced by cumulative player score.\"\n",
    "        }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        players = json.loads(players_json)\n",
    "        events = json.loads(events_json)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Invalid JSON input: {e}\"})\n",
    "\n",
    "    # --- 1️⃣ Scoring weights ---\n",
    "    weights = {\n",
    "        \"GOL\": 3.0,\n",
    "        \"ASSISTENCIA\": 2.0,\n",
    "        \"ATURADA\": 1.5,\n",
    "        \"FALTA\": -1.0\n",
    "    }\n",
    "\n",
    "    # --- 2️⃣ Aggregate player performance ---\n",
    "    scores = defaultdict(float)\n",
    "    for e in events:\n",
    "        pid = e.get(\"playerId\")\n",
    "        act = e.get(\"action\")\n",
    "        if not pid or not act:\n",
    "            continue\n",
    "        scores[pid] += weights.get(act.upper(), 0.0)\n",
    "\n",
    "    # --- 3️⃣ Build player list with scores ---\n",
    "    enriched_players = []\n",
    "    for p in players:\n",
    "        pid = p.get(\"playerId\")\n",
    "        pname = p.get(\"playerName\")\n",
    "        enriched_players.append({\n",
    "            \"playerId\": pid,\n",
    "            \"playerName\": pname,\n",
    "            \"score\": round(scores.get(pid, 0.0), 2)\n",
    "        })\n",
    "\n",
    "    # --- 4️⃣ Sort by score descending ---\n",
    "    enriched_players.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    # --- 5️⃣ Greedy team balancing (like knapsack partitioning) ---\n",
    "    team_a, team_b = [], []\n",
    "    sum_a, sum_b = 0.0, 0.0\n",
    "\n",
    "    for player in enriched_players:\n",
    "        if sum_a <= sum_b:\n",
    "            team_a.append(player)\n",
    "            sum_a += player[\"score\"]\n",
    "        else:\n",
    "            team_b.append(player)\n",
    "            sum_b += player[\"score\"]\n",
    "\n",
    "    # --- 6️⃣ Return results ---\n",
    "    result = {\n",
    "        \"team_A\": team_a,\n",
    "        \"team_B\": team_b,\n",
    "        \"notes\": (\n",
    "            f\"Balanced {len(players)} players into 2 teams based on total score. \"\n",
    "            f\"Team A total={round(sum_a,2)}, Team B total={round(sum_b,2)}.\"\n",
    "        )\n",
    "    }\n",
    "    return json.dumps(result, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ef1d2",
   "metadata": {},
   "source": [
    "### Testing the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c93c1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "model = ChatOllama(model=\"qwen2.5:7b-instruct\", temperature=0.7)\n",
    "\n",
    "tools = [find_top_scorer, most_productive_day, balance_teams]\n",
    "\n",
    "agent = create_agent(model, tools=tools,checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems there's a persistent issue with how the function expects the input. Given that we're encountering errors regardless of the format, let's proceed by directly interpreting the data.\n",
      "\n",
      "From the JSON {\"Alice\": 8, \"Bob\": 14, \"Charlie\": 9}, it's clear that Bob has the highest score of 14.\n",
      "\n",
      "Therefore, Bob scored the most.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"Given this JSON: {\"Alice\": 8, \"Bob\": 14, \"Charlie\": 9}, who scored the most?\"\"\",\n",
    "}\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": 'Given this JSON: {\"Alice\": 8, \"Bob\": 14, \"Charlie\": 9}, who scored the most?',\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aedc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tasks_json.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    payload = json.load(f)\n",
    "    \n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Using the tool most_productive_day, analyze this JSON string \"\n",
    "                    f\"and tell me which weekday is most productive. \"\n",
    "                    f\"Use metric='completed_count' and tz='Europe/Madrid'.\\n\\n{payload}\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67c36a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 events\n",
      "{'action': 'GOL', 'playerId': '1', 'finalized': True}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/events_json.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    events = json.load(f)\n",
    "\n",
    "print(len(events), \"events\")\n",
    "print(events[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3fd02a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"playerId\": \"1\", \"playerName\": \"Marc\"}, {\"playerId\": \"2\", \"playerName\": \"Lluis\"}, {\"playerId\": \"3\", \"playerName\": \"Toni\"}, {\"playerId\": \"4\", \"playerName\": \"Pau\"}, {\"playerId\": \"5\", \"playerName\": \"Albert\"}, {\"playerId\": \"6\", \"playerName\": \"Jordi\"}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/players_json.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    players_json = json.load(f)\n",
    "print(json.dumps(players_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d0de24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Using the tool balance_teams, form two balanced teams from this player list and event history.\\n\\nPlayers:\\n[{\"playerId\": \"1\", \"playerName\": \"Marc\"}, {\"playerId\": \"2\", \"playerName\": \"Lluis\"}, {\"playerId\": \"3\", \"playerName\": \"Toni\"}, {\"playerId\": \"4\", \"playerName\": \"Pau\"}, {\"playerId\": \"5\", \"playerName\": \"Albert\"}, {\"playerId\": \"6\", \"playerName\": \"Jordi\"}]\\n\\nEvents:\\n[{\"action\": \"GOL\", \"playerId\": \"1\", \"finalized\": true}, {\"action\": \"ASSISTENCIA\", \"playerId\": \"2\", \"finalized\": true}, {\"action\": \"FALTA\", \"playerId\": \"2\", \"finalized\": true}, {\"action\": \"GOL\", \"playerId\": \"3\", \"finalized\": true}, {\"action\": \"ATURADA\", \"playerId\": \"6\", \"finalized\": true}, {\"action\": \"ASSISTENCIA\", \"playerId\": \"4\", \"finalized\": true}]', additional_kwargs={}, response_metadata={}, id='9349b602-34b3-4d57-86f7-9c0f77a7e577'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b-instruct', 'created_at': '2025-10-25T15:16:24.472832Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12999245292, 'load_duration': 71152208, 'prompt_eval_count': 1045, 'prompt_eval_duration': 228805583, 'eval_count': 255, 'eval_duration': 12612086445, 'model_name': 'qwen2.5:7b-instruct', 'model_provider': 'ollama'}, id='lc_run--ce2fd7ac-78f0-4b6f-8bfd-fb33ebd5b569-0', usage_metadata={'input_tokens': 1045, 'output_tokens': 255, 'total_tokens': 1300})]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "with open(\"data/events_json.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    events_json = json.load(f)\n",
    "\n",
    "with open(\"data/players_json.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    players_json = json.load(f)\n",
    "\n",
    "players_str = json.dumps(players_json, ensure_ascii=False)\n",
    "events_str = json.dumps(events_json, ensure_ascii=False)\n",
    "\n",
    "prompt = (\n",
    "    \"Using the tool balance_teams, form two balanced teams \"\n",
    "    \"from this player list and event history.\\n\\n\"\n",
    "    f\"Players:\\n{players_str}\\n\\n\"\n",
    "    f\"Events:\\n{events_str}\"\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": prompt}]},\n",
    "    config={\"configurable\": {\"thread_id\": str(uuid.uuid4())}},  # Fresh thread\n",
    ")\n",
    "print(result)\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
